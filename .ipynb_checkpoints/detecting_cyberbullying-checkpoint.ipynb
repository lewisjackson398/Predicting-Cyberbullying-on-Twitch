{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Chat              Label\n",
      "0                            is fatty streaming tonight      cyberbullying\n",
      "1                               is still fat and boring      cyberbullying\n",
      "2        lets be real if a girl watch twitch she is fat      cyberbullying\n",
      "3                              good morning fatty fucks      cyberbullying\n",
      "4     my lab manager is a piece of shit tried to tak...      cyberbullying\n",
      "...                                                 ...                ...\n",
      "1195            drunk is my favorate thing to watch now  non-cyberbullying\n",
      "1196             i litterly just got back what happened  non-cyberbullying\n",
      "1197                       Rather funny than gnomes LUL  non-cyberbullying\n",
      "1198                                  yeah shes smashed  non-cyberbullying\n",
      "1199  Haha I just cant even right now this is soo mu...  non-cyberbullying\n",
      "\n",
      "[1200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Vocabulary:  1802\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    #only alphabet allowed\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Chat'][i])\n",
    "    #set to lowercase\n",
    "    review = review.lower()\n",
    "    #tokenize\n",
    "    review = review.split()\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "#bag of words transformer\n",
    "bow_transformer = CountVectorizer(stop_words='english')\n",
    "bow_transformer = bow_transformer.fit(corpus)\n",
    "\n",
    "print('Length of the Vocabulary: ',len(bow_transformer.vocabulary_))\n",
    "messages_bow = bow_transformer.transform(corpus)\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "X = tfidf_transformer.transform(messages_bow)\n",
    "\n",
    "y = []\n",
    "for row in df[\"Label\"]:\n",
    "    y.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1598)\t0.6238220562606246\n",
      "  (0, 1486)\t0.5782484390789163\n",
      "  (0, 534)\t0.5258086960345586\n",
      "  (1, 529)\t0.5357315061116403\n",
      "  (1, 168)\t0.8443883901140242\n",
      "  (2, 1708)\t0.40553282880344904\n",
      "  (2, 1638)\t0.43251899188951504\n",
      "  (2, 1227)\t0.40553282880344904\n",
      "  (2, 890)\t0.450962166007829\n",
      "  (2, 640)\t0.44116271779754834\n",
      "  (2, 529)\t0.29329533312896516\n",
      "  (3, 1025)\t0.5535288408980124\n",
      "  (3, 657)\t0.36588208558684243\n",
      "  (3, 605)\t0.5535288408980124\n",
      "  (3, 534)\t0.5033308494765925\n",
      "  (4, 1762)\t0.20370758921586832\n",
      "  (4, 1614)\t0.2399047183787652\n",
      "  (4, 1562)\t0.2647069281573192\n",
      "  (4, 1454)\t0.2647069281573192\n",
      "  (4, 1451)\t0.2647069281573192\n",
      "  (4, 1360)\t0.2647069281573192\n",
      "  (4, 1350)\t0.15174306000294704\n",
      "  (4, 1313)\t0.2647069281573192\n",
      "  (4, 1232)\t0.18231577067865057\n",
      "  (4, 1136)\t0.2319201902357586\n",
      "  :\t:\n",
      "  (1193, 947)\t0.449231900466714\n",
      "  (1193, 425)\t0.5275808298728863\n",
      "  (1194, 1387)\t0.5878910274430733\n",
      "  (1194, 615)\t0.5556692178840351\n",
      "  (1194, 199)\t0.5878910274430733\n",
      "  (1195, 1708)\t0.4316655374271083\n",
      "  (1195, 1558)\t0.42587652430763445\n",
      "  (1195, 537)\t0.5778831040968051\n",
      "  (1195, 455)\t0.5462098203445774\n",
      "  (1196, 907)\t0.6241617055620022\n",
      "  (1196, 846)\t0.35602394618260036\n",
      "  (1196, 701)\t0.565679709397971\n",
      "  (1196, 664)\t0.40456838906410936\n",
      "  (1197, 947)\t0.543990223977145\n",
      "  (1197, 648)\t0.6388656137518995\n",
      "  (1197, 613)\t0.543990223977145\n",
      "  (1198, 1781)\t0.5163165461112783\n",
      "  (1198, 1401)\t0.7006035583867893\n",
      "  (1198, 1345)\t0.49251586592463115\n",
      "  (1199, 1423)\t0.3808921569987813\n",
      "  (1199, 1268)\t0.5864421535436102\n",
      "  (1199, 846)\t0.22986064069985962\n",
      "  (1199, 729)\t0.40297910036426265\n",
      "  (1199, 697)\t0.40297910036426265\n",
      "  (1199, 686)\t0.3652212212895322\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          idf_weights\n",
      "ability      7.397763\n",
      "able         7.397763\n",
      "absolute     6.992298\n",
      "abusers      7.397763\n",
      "account      6.481472\n",
      "...               ...\n",
      "yt           7.397763\n",
      "yum          7.397763\n",
      "yummy        7.397763\n",
      "zenbob       7.397763\n",
      "zone         7.397763\n",
      "\n",
      "[1802 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=bow_transformer.get_feature_names(),columns=[\"idf_weights\"])\n",
    " \n",
    "# sort ascending\n",
    "print(df_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection - setting train and test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler(with_mean=False)\n",
    "\n",
    "#x_train_std = sc.fit_transform(X_train)\n",
    "#x_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       0.82      0.88      0.85       152\n",
      "non-cyberbullying       0.87      0.80      0.84       148\n",
      "\n",
      "         accuracy                           0.84       300\n",
      "        macro avg       0.85      0.84      0.84       300\n",
      "     weighted avg       0.85      0.84      0.84       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[134  18]\n",
      " [ 29 119]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Naive Bayes Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       0.85      0.76      0.80       152\n",
      "non-cyberbullying       0.77      0.86      0.81       148\n",
      "\n",
      "         accuracy                           0.81       300\n",
      "        macro avg       0.81      0.81      0.81       300\n",
      "     weighted avg       0.81      0.81      0.81       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[115  37]\n",
      " [ 21 127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Decision Tree Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       0.87      0.68      0.76       152\n",
      "non-cyberbullying       0.73      0.89      0.80       148\n",
      "\n",
      "         accuracy                           0.79       300\n",
      "        macro avg       0.80      0.79      0.78       300\n",
      "     weighted avg       0.80      0.79      0.78       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[104  48]\n",
      " [ 16 132]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Random Forest Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       0.78      0.74      0.76       152\n",
      "non-cyberbullying       0.75      0.79      0.77       148\n",
      "\n",
      "         accuracy                           0.76       300\n",
      "        macro avg       0.76      0.76      0.76       300\n",
      "     weighted avg       0.76      0.76      0.76       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[112  40]\n",
      " [ 31 117]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_std, y_train)\n",
    "y_pred = lr.predict(x_test_std)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Logistic Regression Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       0.64      0.78      0.71       152\n",
      "non-cyberbullying       0.71      0.55      0.62       148\n",
      "\n",
      "         accuracy                           0.67       300\n",
      "        macro avg       0.68      0.67      0.66       300\n",
      "     weighted avg       0.68      0.67      0.67       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[119  33]\n",
      " [ 66  82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(x_train_std, y_train)\n",
    "y_pred = svm.predict(x_test_std)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Support Vector Machine Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor Results:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    cyberbullying       1.00      0.15      0.26       152\n",
      "non-cyberbullying       0.53      1.00      0.70       148\n",
      "\n",
      "         accuracy                           0.57       300\n",
      "        macro avg       0.77      0.58      0.48       300\n",
      "     weighted avg       0.77      0.57      0.48       300\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      " [[ 23 129]\n",
      " [  0 148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_std, y_train)\n",
    "y_pred = knn.predict(x_test_std)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('K-Nearest Neighbor Results:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion Matrix\\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyberbullying', 'non-cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['i wish you were dead', 'i wish you were my friend']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "classifier.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyberbullying', 'non-cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['Fuck you', 'Your amazing']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "tree.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyberbullying', 'non-cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['Fuck you', 'Your amazing']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "forest.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyberbullying', 'non-cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['Fuck you', 'Your amazing']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "lr.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyberbullying', 'cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['Fuck you', 'Your amazing']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nearest neighbor testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-cyberbullying', 'non-cyberbullying'], dtype='<U17')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['Fuck you', 'Your amazing']\n",
    "new_test = bow_transformer.transform(test_set)\n",
    "\n",
    "knn.predict(new_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
